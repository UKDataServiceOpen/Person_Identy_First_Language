{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d71e8f5f",
   "metadata": {},
   "source": [
    "# Pattern matching\n",
    "\n",
    "\n",
    "We will start in the same way as the last notebook started  - by downloading/importing the packages needed and importing the .csv file(s) needed. In this case, we only need the .csv file that has the matched abstracts as we are specifically looking at person-first and identity-first patterns that are \"about\" autism (or ASD, Asperger's syndrome, etc.). \n",
    "\n",
    "We could use the same basic approach to look at person-first and identity-first language for other conditions for which there are good noun and adjective forms of the words (diabetes? obesity? cancer? something else?). Doing that would mean using the .csv file with all of the abstracts or potentially creating and entirely new file of abstracts matched to another condition of interest. However, that lies outside the scope of this research, so I will not address it further here. \n",
    "\n",
    "## Get ready \n",
    "\n",
    "As always, we start with code that:\n",
    "* loads up and nicknames some useful packages, \n",
    "* checks file locations,\n",
    "* imports files, and \n",
    "* checks them. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271c801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install nltk\n",
    "!pip install spacy -q\n",
    "!python -m spacy download en_core_web_lg -q\n",
    "\n",
    "import os                         # os is a module for navigating your machine (e.g., file directories).\n",
    "import nltk                       # nltk stands for natural language tool kit and is useful for text-mining. \n",
    "from nltk import word_tokenize    # and some of its key functions\n",
    "from nltk import sent_tokenize  \n",
    "tokenizer = nltk.tokenize.punkt.PunktSentenceTokenizer()\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import wordnet                    # Finally, things we need for lemmatising!\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "nltk.download('averaged_perceptron_tagger')        # Like a POS-tagger...\n",
    "nltk.download('wordnet')\n",
    "nltk.download('webtext')\n",
    "from nltk.corpus import webtext\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "import numpy as np\n",
    "import statistics\n",
    "\n",
    "import csv                        # csv is for importing and working with csv files\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import statistics\n",
    "import re                         # things we need for RegEx corrections\n",
    "import string \n",
    "import spacy \n",
    "from spacy.matcher import Matcher \n",
    "from spacy.tokens import Span \n",
    "from spacy import displacy \n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "nlp.max_length = 1500000 #or any large value, as long as you don't run out of RAM\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "print(os.listdir(\"..\\\\output\")  )    \n",
    "\n",
    "# the '%%capture' at the top of this cell suppresses the output (which is normally quite long and annoying looking). \n",
    "# You can remove or comment it out if you prefer to see the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4e4ea5",
   "metadata": {},
   "source": [
    "## Import\n",
    "\n",
    "Having checked the contents of the output folder and seen the files we expected to see, we can now import the specific file of interest for this step of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b74ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_texts = pd.read_csv('..\\\\output\\\\matched_abstracts_no_null_texts.csv')    # one for just those that match the keyword\n",
    "len(matched_texts)                                                                # check the length "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d89f25",
   "metadata": {},
   "source": [
    "## Cleaning phase\n",
    "\n",
    "Cleaning begins by turning any instances of extra whitespaces (two or more in a row) into a single whitespace. Then, identifying any run-on sentences (where a lowercase letter, a full stop, and an uppercase letter are clustered without a whitespace) and inserting a whitespace between the full stop and the uppercase letter. Both of these steps will improve the sentence tokenisation that happens next. \n",
    "\n",
    "Then, we proceed to sentence tokenising the text. Like word tokens, sentence tokens become the unit for analysisis. As a trivial example, sentence tokenisation would turn a short text such as \n",
    "\n",
    "\n",
    "''' The cat named Cat is one of five cats. Honestly, I wonder why I have so many cats.\n",
    "''' \n",
    "\n",
    "into a list of sentence tokens like\n",
    "\n",
    "''' [[The cat named Cat is one of five cats.]\n",
    "\n",
    "[Honestly, I wonder why I have so many cats.]]\n",
    "\n",
    "''' \n",
    "\n",
    "An important difference is that the punctuation within the sentences that contributes to its structured and meaning (e.g. the comma and the full stops) are retained. This punctuation, like the capitalisation at the start of the sentences or for the poper nouns, is also retained as it helps the sentence-tokenisation process identify the words within the sentence correctly for their parts of speech (e.g. which of the words are nouns, verbs, etc. ). \n",
    "\n",
    "\n",
    "\n",
    "The sentence tokens are then put on individual rows, filtered to retain only those that contain one or more of the keywords of interest, and then filtered to ensure that there are no empty rows or duplicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cfa42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_errors (input):\n",
    "    no_extra_spaces = re.sub(r'(\\s)(\\s+)', r'\\1', input)               # turn 2+ sequential whitespaces into 1\n",
    "    no_run_ons1 = re.sub(r'([a-z].)([A-Z])', r'\\1 \\2', no_extra_spaces) # identifies run-ons (e.g. \"word.New sentence \")\n",
    "    no_run_ons2 = re.sub(r'([A-Z].)([A-Z])', r'\\1. \\2', no_run_ons1) # identifies run-ons (e.g. \"ACRONYM.New sentence \")\n",
    "\n",
    "    return(no_run_ons2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2edc6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_run_ons = [remove_errors(abstract) for abstract in matched_texts['Text'] ] \n",
    "                                             # create abstract list without extra spaces/run-ons \n",
    "                                             # this is to improve sentence tokenisation later \n",
    "matched_texts['Sentence'] = no_run_ons       # copy the no extra space/run-on abstract list back into df as a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17421e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences  = [sent_tokenize(abstract) for abstract in matched_texts['Text'] ] # create tokenised list of cleaner abstracts\n",
    "matched_texts['Sentence'] = sentences                                   # copy that list back into df as a new column\n",
    "sentence_per_row = matched_texts.explode('Sentence')                    # explode column in new df with 1 row/sentence token\n",
    "print(\"How many sentences in total: \" + str(len(sentence_per_row)))     # check the length of new df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd66d796",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentence_per_row[['Text','Sentence']])                            # have a look. The selected rows should have \n",
    "                                                                        # 'Text' the same, but 'Sentence' different "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3795c76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_sentences = sentence_per_row[sentence_per_row['Sentence'].str.contains('[Aa]utis|ASD|AS|[Aa]sperger')]\n",
    "                                                     # create a new data frame with only the sentences that contain keywords\n",
    "print(\"How many matching sentences: \" + str(len(matched_sentences)))            # check the length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8cdb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_sentences = matched_sentences[~matched_sentences['Sentence'].isnull()]  # remove any rows with empty 'Sentence' column\n",
    "matched_sentences = matched_sentences.drop_duplicates()                         # drop any duplicates\n",
    "print(\"Now how many matching sentences: \" + str(len(matched_sentences)))        # check length of remaining data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847a9ab3",
   "metadata": {},
   "source": [
    "In working with the matching sentences, it became clear there were several common errors, variations on how things were written and other annoying minor differences in the texts that made the manual checking more time-consuming than it needed to be.\n",
    "\n",
    "Further, the minor differences meant that the counting steps later on were counting \"child with ASD\" separately from \"child with autism\" when perhaps the more interesting distinction there is whether \"child with autism/ASD\" is more or less common than \"patient with autism/ASD\" or \"proband with autism/ASD\" or any other common person-nouns. \n",
    "\n",
    "Thus, this tidy_up_terminology function corrects several importing errors, spelling and style differences, and consolidates on terminology. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6a85b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_up_terminology (input):\n",
    "    space1 = re.sub(r'([A-Z]).(A-Z)', r'\\1. \\2', input)                 # removes multiple white spaces between words\n",
    "    space2 = re.sub(r'([a-z])(disorder|disability|spectrum)', r'\\1 \\2', space1) # adds a space in select run-ons\n",
    "    space3 = re.sub(r'([a-z])(disorder|spectrum)', r'\\1 \\2', space2)    # a second go at adding a space in select run-ons      \n",
    "    space4 = re.sub(r'(spec) (trum)', r'\\1\\2', space3)                  # removes a space between 'spec' and 'trum'\n",
    "    no_apost = re.sub(r'([Aa]sperger[\\S*?]s)', r'asperger', space4)     # lowercases, removes ' and S from '[Aa]sperger's' \n",
    "    lower1 = re.sub(r'Autis', r'autis', no_apost)                       # lowercases 'Autism' and 'Autistic'\n",
    "    lower2 = re.sub(r'[Aa]spergers|[Aa]sperger', r'asperger', lower1)   # lowercases/removes S from '[Aa]spergers' & '[Aa]sperger'\n",
    "    lower3 = re.sub(r'[Ss]pectrums|[Ss]pectra', r'spectrum', lower2)    # lowercases and removes various plurals for spectrum\n",
    "    lower4 = re.sub(r'[Ss]yndromes|[Ss]yndrome', r'syndrome', lower3)   # lowercases and removes plurals for syndrome\n",
    "    lower5 = re.sub(r'[Dd]isorders|Disorder', r'disorder', lower4)      # lowercases and removes plurals for disorder\n",
    "    lower6 = re.sub(r'[Dd]iseases|Disease', r'disease', lower5)         # lowercases and removes plurals for disease\n",
    "    plur = re.sub(r'ASDs', r'ASD', lower6)                              # removes plural from instances of more than one ASD\n",
    "    stan0 = re.sub(r'(autism|autistic|asperger) syndrome', r'autism spectrum', plur ) # turns select 'syndrome' to 'spectrum'\n",
    "    stan1 = re.sub(r'spectrum disease', r'spectrum disorder', stan0 )   # turns select 'disease' to 'disorder'\n",
    "    stan2 = re.sub(r'(autism|autistic|asperger) spectrum disorder \\(ASD\\)', r'ASD', stan1) # abbreviates various ASD definitions\n",
    "    stan3 = re.sub(r'(autism|autistic|asperger) spectrum disorder', r'ASD', stan2) # abbreviates various options to ASD\n",
    "    stan4 = re.sub(r'(autism|autistic|asperger) spectrum \\(AS\\)', r'ASD', stan3)  # standardises more options to ASD\n",
    "    stan5 = re.sub(r'(autism|autistic|asperger) spectrum', r'ASD', stan4)         # standardises more options to ASD\n",
    "    stan6 = re.sub(r'AS ', r'ASD ', stan5)                              # standardises 'AS ' to 'ASD ' - note trailing space\n",
    "    stan7 = re.sub(r'(autism|autistic|asperger) disorder', r'ASD', stan6) # abbreviates various ASD definitions\n",
    "    aut0 = re.sub(r'asperger autism', r'autism', stan7)                  # standardises 'asperger autism' to 'autism'\n",
    "    ID1 = re.sub(r'[Ii]ntellectual [Dd]isability \\(ID\\)', r'ID', aut0)\n",
    "    ID2 = re.sub(r'[Ii]ntellectual [Dd]isability', r'ID', ID1)\n",
    "\n",
    "    return(ID2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c95f250",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Optional cell code block to test or understand what the tidy_up_terminology function does\n",
    "    \n",
    "tidy_test = \"Autism spectrum intellectual disability and autism ID, ASD \\\n",
    "            Autisticspectrum autisticspectrumdisorder ASD \\\n",
    "            Asperger's syndrome asperger's syndrome \\\n",
    "            intellectual disability Intellectual Disability (ID)\\\n",
    "            aspergers syndrome autism spectrum  ASDs ASD ID, and autism \"\n",
    "\n",
    "tidy_up_terminology(tidy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1708235",
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_text = [tidy_up_terminology(sentence) for sentence in matched_sentences['Sentence'] ] \n",
    "                                             # create abstract list without extra spaces/run-ons \n",
    "                                             # this is to improve sentence tokenisation later \n",
    "matched_sentences['Sentence'] = tidy_text    # copy the no extra space/run-on abstract list back into df as a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fa94a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "backup = matched_sentences                    # A backup is useful at this step because the next may not go the way you expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dd0c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_sentences = backup                    # If you need the backup, re-run this step. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f0de07",
   "metadata": {},
   "source": [
    "## Extraction\n",
    "\n",
    "Following the cleaning phase, we move on to the extraction phase. This has two parts, first for the person-first extraction and then for the identity-first extraction. \n",
    "\n",
    "The results of both extractions are saved in their own column to make it easy to read and also to allow for a single sentence-token to contain both kinds of patterns. \n",
    "\n",
    "### Person-first pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d739a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_1 = [{\"POS\": \"NOUN\"},                                        # define the person-first pattern - start with a noun\n",
    "             {'DEP':'amod', 'OP':\"?\"},                               # followed by an optional modifier\n",
    "             {\"TEXT\": {\"REGEX\": \"(with|by|from)\"}},                  # followed by some words that set up the p-f pattern\n",
    "             {'DEP':'amod', 'OP':\"?\"},                               # then space for up to three optional modifiers\n",
    "             {'DEP':'amod', 'OP':\"?\"},\n",
    "             {'DEP':'amod', 'OP':\"?\"},\n",
    "             {\"TEXT\": {\"REGEX\": \"(^[Aa]utis|^[Aa]sperger|^ASD|^AS$)\"}}] # finally, the keywords (original format, just in case)\n",
    "\n",
    "# Matcher class object \n",
    "matcher = Matcher(nlp.vocab)                                         # define a matcher class object\n",
    "matcher.add(\"matching_1\", [pattern_1])                               # add my three person-first patterns to it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d072ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pattern_match(input):                                               # define a function that applies the person-first\n",
    "    thingy = nlp(input)                                                      # matcher class object to strings\n",
    "    match = matcher(thingy)                                                  # and returns any matches to the pattern(s)\n",
    "    if match == []:\n",
    "        out_value = ''\n",
    "    else:\n",
    "        hold_multi_spans = []\n",
    "        for match_id, start, end in match:\n",
    "                string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "                span = thingy[start:end]  # The matched span\n",
    "                hold_multi_spans.append(span)\n",
    "        out_value = hold_multi_spans\n",
    "    return out_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffd7373",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_sentences['Person-first'] = matched_sentences.apply(lambda row: find_pattern_match(row.Sentence), axis = 1)\n",
    "                                                                        # apply the newly defined person-first matcher function\n",
    "                                                                        # and store the returned output in a new column\n",
    "len(matched_sentences)                                                  # double check length remains same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936cc982",
   "metadata": {},
   "source": [
    "### Identity-first pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc18f3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_a = [{'DEP':'amod', 'OP':\"?\"},                                 # same for identity-first patterns,\n",
    "             {'DEP':'amod', 'OP':\"?\"},                                 # starting with two optional modifiers\n",
    "             {\"TEXT\": {\"REGEX\": \"(^[Aa]utis|^[Aa]sperger|^ASD|^AS$)\"}}, # the keywords (original format, just in case)\n",
    "             {'DEP':'amod', 'OP':\"?\"},                                 # then upt to three more optional modifiers\n",
    "             {'DEP':'amod', 'OP':\"?\"},\n",
    "             {'DEP':'amod', 'OP':\"?\"},\n",
    "             {\"POS\": \"NOUN\"}]                                          # and then a noun\n",
    "\n",
    "# Matcher class object                                         \n",
    "matcher = Matcher(nlp.vocab) \n",
    "matcher.add(\"matching_2\", [pattern_a])            # this overwrites the matcher object to identity-first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f00defd",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_sentences['Identity-first'] = matched_sentences.apply(lambda row: find_pattern_match(row.Sentence), axis = 1)\n",
    "                                                                        # apply the newly overwritten matcher function\n",
    "                                                                        # and store the returned output in a new column\n",
    "len(matched_sentences)                                                  # check the length - why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406db79a",
   "metadata": {},
   "source": [
    "### Consolidation\n",
    "\n",
    "Following the cleaning and extraction phases, the last phase is consolidation. This phase further refines the data by removing all the rows that do not contain a match for one or both of the patterns. For example, there would be a row for \"The child was tested for autism.\" because it contains a keyword of interest. However, this sentence would be eliminated in the consolidation phase as the keyword does not fit into either the person-first or identity-first patterns. \n",
    "\n",
    "Further, this phase goes on to lemmatise the extracted patterns so that they can be counted more easily. This phase also lowercases all occurrences of \"Autistic\", \"Autism\", and \"Asperger's\" as well as removing the apostrophe, the 's' and any non-white characters that might intrude between the 'r' and the 's' of \"Asperger's\". This phase also removes any square brackets, quotes and extra commas introduced by the lemmatisation process. \n",
    "\n",
    "This phase ends by writing out the consolidated data frame to a .csv for manual inspection. I could not find a feasible way of identifying whether or not the nouns matched in the extraction phase are person-nouns or not. As the list is not a totally unreasonable length (in the hundreds) I found it workable to \n",
    "* open in excel, \n",
    "* save the file under another name (e.g. pattern_matches_reviewed), \n",
    "* order the entire data set alphabetically by 'Person-first', \n",
    "* scan through the ordered results check whether each result in the 'Person-first' column is about a person, \n",
    "* removing entire rows if the 'Person-first' match is not about a person (checking the 'Sentence' or 'Text' column if needed)\n",
    "* re-order the entire data set alphabetically by 'Identity-first', \n",
    "* scan through the ordered results check whether each result in the 'Identity-first' column is about a person, \n",
    "* removing entire rows if the 'Identity-first' match is not about a person, \n",
    "* save file again. \n",
    "\n",
    "For example, 'association with autism' matches the person-first pattern but is not about a person, so this row was removed. Many more rows were removed in the 'Identity-first' matches as things like 'autistic behaviours' and 'autism testing' were removed for not being about people. \n",
    "\n",
    "NOTE: There were several instances of \"ASD dataset\" which are not easy to determine if they are about people or not. Do they mean dataset composed from blood tests taken as part of ASD testing? If so, each row in the data set would be a blood test with the possibility that more than one test comes from the same person. Or do they mean a pool of case records, each of which represents a single person? The former would not be \"about people\" but the second would. I did not remove these rows as we cannot be certain. Leaving them out would also have been a valid option, as long as the choice was clear. \n",
    "\n",
    "Coincidentally, during this manual checking part of the consolidation phase I learned that, in the context of human genetics research \"proband\" is a person-noun. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d91446",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_patterns = matched_sentences[(matched_sentences['Person-first'] != '') | (matched_sentences['Identity-first'] != '')]\n",
    "                                                     # keep only rows w/ non-null 'Person-first' and/or 'Identity-first' columns\n",
    "len(matched_patterns)                                # check length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58536fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_patterns = matched_patterns.explode('Person-first')    # explode 'Person-first' column to create 1 row per match\n",
    "                                                               # if there were two matches within the same sentence\n",
    "len(matched_patterns)                                          # check the length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80451426",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_patterns = matched_patterns.explode('Identity-first')  # Do the same for 'Identity-first' column\n",
    "len(matched_patterns)                                          # check the length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba5db63",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_patterns.head(5)                                               # have a look at them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e44521",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lem = WordNetLemmatizer()                         # Define a short way to call the WordNetLemmatizer\n",
    "\n",
    "def consolidate_matched_patterns (input):         # \n",
    "    final_lemma_list = []\n",
    "    temp_lemma_list = []\n",
    "    for phrase in input:                       # start for loop looking at each pattern in the person-first pattern column\n",
    "        phrase_as_string = str(phrase)                               # hold the current pattern\n",
    "        words_in_phrase = phrase_as_string.split() # split the current pattern into words\n",
    "        for word in words_in_phrase :                            # for each word in the split up words\n",
    "            lemma = Lem.lemmatize(word)             # turn that word into a lemma\n",
    "            temp_lemma_list.append(lemma)                # append that lemma to a temporary list\n",
    "        string_lem = str(temp_lemma_list)              # turn that temporary list into a string\n",
    "        stripped_lem = re.sub(r\"\\[|\\]|\\'|\\,\",'', string_lem)  # remove  square brackets, commas and '' marks from the string\n",
    "        final_lemma_list.append(stripped_lem)        # append the string version of the list to the output list\n",
    "        temp_lemma_list = []                               # ensure the temp variable is empty\n",
    "\n",
    "    return(final_lemma_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b670fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_lemma_list = consolidate_matched_patterns(matched_patterns['Person-first'])\n",
    "identity_lemma_list = consolidate_matched_patterns(matched_patterns['Identity-first'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad90adb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_patterns['Person-first'] = person_lemma_list    # copy the person-first output to new column in data frame \n",
    "matched_patterns['Identity-first'] = identity_lemma_list  # copy the identity-first output to new column in data frame \n",
    "matched_patterns = matched_patterns.drop_duplicates()                         # drop any duplicates\n",
    "matched_patterns                                                   # have a look at the data frame with its new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ac2138",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_patterns.to_csv('..\\\\output\\\\pattern_matches_to_review.csv')        \n",
    "                                                            # Write the data frame to a .csv for manual processing in excel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9897ba53",
   "metadata": {},
   "source": [
    "At this point, I open the file in Excel (for example), removed the brackets, quotation marks and commas in the Person-first lemmatised and Identity-first lemmatised columns, then sort by each of one of these columns. I then scan through the results, removing any rows that are obviously not about people (e.g. \"autistic testing\") and checking the 'Text' column on any that are unclear 'autistic quartets'). I then sort by the other column and repeat the step of reviewing and deleting non-person rows. Save under \"pattern_matches_reviewed.csv\" for the next step. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d2281a",
   "metadata": {},
   "source": [
    "## Exlporing statistics for PFL and IFL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388d8be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewed_matches = pd.read_csv('..\\\\output\\\\pattern_matches_reviewed.csv')    # one for just those that match the keyword\n",
    "reviewed_matches.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fbac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are \" + \n",
    "      str(len(reviewed_matches)) + \" rows in the post-manual review data frame coming from \" +\n",
    "      str(reviewed_matches['Title'].nunique()) +\n",
    "      \" unique titles.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2c9802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_PF_nouns(input):\n",
    "    output = []\n",
    "    for thingy in input:\n",
    "        if isinstance(thingy,str):\n",
    "            word_list = thingy.split()\n",
    "            noun = word_list[0]\n",
    "            output.append(noun)\n",
    "        else:\n",
    "            output.append(\"\")\n",
    "    return output\n",
    "\n",
    "def find_IF_nouns(input):\n",
    "    output = []\n",
    "    for thingy in input:\n",
    "        if isinstance(thingy,str):\n",
    "            word_list = thingy.split()\n",
    "            noun = word_list[-1]\n",
    "            output.append(noun)\n",
    "        else:\n",
    "            output.append(\"\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eda37d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewed_matches['PF_nouns'] = find_PF_nouns(reviewed_matches['Person-first'])      # applies the new functions to find\n",
    "reviewed_matches['IF_nouns'] = find_IF_nouns(reviewed_matches['Identity-first'])    # pf and if nouns and put them in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e3d86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewed_matches.to_csv('..\\\\output\\\\nouns_to_review.csv')        \n",
    "                                                            # Write the data frame to a .csv for manual processing in excel\n",
    "                                                            # This second manual processing revealed one row that was not about \n",
    "                                                            # 'people' and which should have been removed before also a row \n",
    "                                                            # in which a preceding adjective had been counted as a noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30e1cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewed_matches = pd.read_csv('..\\\\output\\\\nouns_reviewed.csv')    # one for just those that match the keyword\n",
    "reviewed_matches.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d514d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_instances = reviewed_matches.iloc[:,12].tolist()                         # copies the Person-first column to a list,   \n",
    "print(len(pf_instances))                                                    # check length of list before filtering\n",
    "filtered_pf_instances = [instance for instance in pf_instances              # filters the list to remove non-string items\n",
    "                         if isinstance(instance, str)] \n",
    "                                                                            \n",
    "print(\"Total count of PFL instances: \",                                     # Print length of list after filtering\n",
    "      len(filtered_pf_instances))                                           # This represents total count of PF instances\n",
    "\n",
    "pf_instance_dict = dict((instance, filtered_pf_instances.count(instance))   # creates a dict from the \n",
    "                        for instance in filtered_pf_instances)              # filtered list that counts instances\n",
    "                                                                 \n",
    "pf_instance_dict = dict(sorted(pf_instance_dict.items(),                    # sorts that dict according to count \n",
    "                               key = lambda item: item[1], reverse=True))   # in descending order\n",
    "                                                                 \n",
    "print(\"Count of unique PFL instances: \", len(pf_instance_dict))              # This represents count of unique PF instances\n",
    "pf_instance_dict                                                             # Prints the sorted, filtered dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfcbe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "if_instances = reviewed_matches.iloc[:,13].tolist()                         # copies the Identity-first column to a list,   \n",
    "print(len(if_instances))                                                    # check length of list before filtering\n",
    "filtered_if_instances = [instance for instance in if_instances              # filters the list to remove non-string items\n",
    "                         if isinstance(instance, str)] \n",
    "                                                                            \n",
    "print(\"Total count of IFL instances: \",                                     # check length of list after filtering\n",
    "      len(filtered_if_instances))                                           # This represents total count of IF instances\n",
    "\n",
    "if_instance_dict = dict((instance, filtered_if_instances.count(instance))   # creates a dict from the \n",
    "                        for instance in filtered_if_instances)              # filtered list that counts instances\n",
    "                                                                 \n",
    "if_instance_dict = dict(sorted(if_instance_dict.items(),                    # sorts that dict according to count \n",
    "                               key = lambda item: item[1], reverse=True))   # in descending order\n",
    "                                                                 \n",
    "print(\"Count of unique IFL instances: \", len(if_instance_dict))              # This represents count of unique IF instances\n",
    "if_instance_dict                                                             # Prints the sorted, filtered dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94456792",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_output = pd.DataFrame.from_dict([pf_instance_dict,               # copy both instances dicts to dataframe\n",
    "                                           if_instance_dict]).transpose()  # and transpose it to be long\n",
    "                                                                           \n",
    "print(list(instances_output.columns))                                      # check column names in new dataframe\n",
    "instances_output = instances_output.rename(columns={0: 'PF_count',         # rename column names according to source dict\n",
    "                                                    1: 'IF_count'}) \n",
    "\n",
    "instances_output = instances_output[(instances_output['PF_count'] > 4)     # remove the rows that are below 4 instances for at\n",
    "                            | (instances_output['IF_count'] > 4)]          # least one of the sources\n",
    "instances_output.to_csv('..\\\\output\\\\instances_count.csv')                 # write popular noun data frame to .csv \n",
    "                                                                           # to make it easy to compare or use \n",
    "instances_output                                                           # print it to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80834e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_nouns = reviewed_matches.iloc[:,14].tolist()                            # Same again, but for just the Person-first nouns\n",
    "filtered_pf_nouns = [noun for noun in pf_nouns if isinstance(noun, str)] \n",
    "\n",
    "print(\"Total count of PFL nouns: \",                                        # check length of list after filtering\n",
    "      len(filtered_pf_nouns))                                          # Should be the same as total PF instances\n",
    "\n",
    "pf_noun_dict = dict((noun, filtered_pf_nouns.count(noun)) for noun in filtered_pf_nouns)\n",
    "pf_noun_dict = dict(sorted(pf_noun_dict.items(), key = lambda item: item[1], reverse=True))                                                                 \n",
    "print(\"Count of unique PFL nouns: \", len(pf_noun_dict))                    # This represents count of unique PF nouns\n",
    "pf_noun_dict                                                               # Prints the sorted, filtered dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11094e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "if_nouns = reviewed_matches.iloc[:,15].tolist()                        # One more time, but for Identity-first nouns\n",
    "filtered_if_nouns = [noun for noun in if_nouns if isinstance(noun, str)] \n",
    "\n",
    "print(\"Total count of IFL nouns: \",                                        # check length of list after filtering\n",
    "      len(filtered_if_nouns))                                              # Should be the same as total IF instances\n",
    "\n",
    "\n",
    "if_noun_dict = dict((noun, filtered_if_nouns.count(noun)) for noun in filtered_if_nouns)\n",
    "if_noun_dict = dict(sorted(if_noun_dict.items(), key = lambda item: item[1], reverse=True))\n",
    "\n",
    "print(\"Count of unique IFL nouns: \", len(if_noun_dict))                    # This represents count of unique IF nouns\n",
    "if_noun_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f89988",
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns_output = pd.DataFrame.from_dict([pf_noun_dict, if_noun_dict]).transpose() # copy & transpose both noun dicts to dataframe \n",
    "print(list(nouns_output.columns))                                               # check column names in new dataframe\n",
    "nouns_output = nouns_output.rename(columns={0: 'PF_count', 1: 'IF_count'})      # rename column names according to source dict\n",
    "nouns_output = nouns_output[(nouns_output['PF_count'] > 0)                      # remove the rows that are not multiple for at\n",
    "                            | (nouns_output['IF_count'] > 0)]                   # least one of the sources\n",
    "nouns_output.to_csv('..\\\\output\\\\nouns_count.csv')                              # write popular noun data frame to .csv \n",
    "                                                                                # to make it easy to compare or use \n",
    "nouns_output                                                                    # print it to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9e02f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# back in the big data frame, we want to track how many instances of each occur by year\n",
    "PFL_by_year = reviewed_matches.groupby(['Year'])['Person-first'].count()      # group by year and Person-first, then count    \n",
    "IFL_by_year = reviewed_matches.groupby(['Year'])['Identity-first'].count()    # group by year and Identity-first, then count    \n",
    "person_identity_count = pd.concat([PFL_by_year,IFL_by_year],axis=1)           # concatenate the groups into new data frame\n",
    "person_identity_count = person_identity_count.rename(                         # Rename the columns in new data frame\n",
    "    columns={\"Person-first\": \"PFL\", \"Identity-first\": \"IFL\"})    \n",
    "\n",
    "person_identity_count = person_identity_count.rename_axis('Year').reset_index()         # rename axis, reset index\n",
    "person_identity_count = person_identity_count.sort_values(by=['Year']).astype('Int64')  # retype and sort by value of year\n",
    "\n",
    "print(person_identity_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1207db21",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_identity_count['Year'] = pd.to_datetime(person_identity_count['Year'].astype(str), format=\"%Y\") \n",
    "                                                                     # reformat the Year to be a date as string in format YEAR \n",
    "person_identity_count = person_identity_count.set_index('Year')      # set newly reformatted Year column to be the index\n",
    "\n",
    "print(person_identity_count)                                         # Print it to make sure nothing is gone terribly wrong\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325e18cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_identity_count.plot()                        # Plot the counts of PFL and IFL by year\n",
    "plt.ylabel(\"Count of total pattern matches\")        # Set y label\n",
    "plt.xlabel(\"Year\")                                  # Set x label\n",
    "plt.title(\"Instances of PFL and IFL by year\")       # Set plot title\n",
    "plt.legend(loc=\"upper left\", frameon=False)         # Set position for legend and set legend frame to be false\n",
    "plt.show()                                          # Show that plot!\n",
    "\n",
    "plt.savefig('..\\\\output\\\\matches_count.jpg',  )    # we can right click on the plot above to save it, or save it via command"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efde442",
   "metadata": {},
   "source": [
    "## Chart person-first or identity-first by year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b82b88",
   "metadata": {},
   "source": [
    "## Count abstracts by the structures they use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd85bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# back in the big data frame, we want to track how many instances of each occur by abstract title \n",
    "# to see if authors mix their use or if they use both more or less evenly\n",
    "\n",
    "person_by_title = reviewed_matches.groupby(['Title'])['Person-first'].count()     # group and count by Title & Person-first\n",
    "identity_by_title = reviewed_matches.groupby(['Title'])['Identity-first'].count() # group and count by Title & Identity-first\n",
    "title = pd.concat([person_by_title,identity_by_title],axis=1)                     # concatenate the groups into new data frame\n",
    "print(list(title.columns))                                                        # check column names in new dataframe\n",
    "title = title.rename(columns={'Person-first': 'PF_count', \n",
    "                              'Identity-first': 'IF_count'})                 # rename column names according to source dict\n",
    "\n",
    "#title = title[(title['PF_count'] > 0)                                  # OPTIONAL - uncomment these 2 lines to \n",
    "#                            & (title['IF_count'] > 0)]                 # select only the abstracts that contain both patterns\n",
    "\n",
    "print(len(title))                                                            # Print how many titles have at least one of each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975b4d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "title.sort_values(by=['PF_count'], ascending=False)        # sort by PFL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53be701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "title.sort_values(by=['IF_count'], ascending=False)        # Sort by IFL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d43199",
   "metadata": {},
   "outputs": [],
   "source": [
    "co_occurence_counts = title.groupby(by=['PF_count', 'IF_count']).size().to_frame('size').reset_index()\n",
    "co_occurence_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e45eef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = plt.scatter(x=co_occurence_counts['PF_count'], \n",
    "                     y=co_occurence_counts['IF_count'], \n",
    "                     c=co_occurence_counts['size'],\n",
    "                     s=200)\n",
    "plt.ylabel(\"Instance of IFL\")\n",
    "plt.xlabel(\"Instance of PFL\")\n",
    "plt.title(\"Abstracts using both PFL and IFL\")\n",
    "plt.ylim([-1, 10])\n",
    "plt.xlim([-1, 10])\n",
    "\n",
    "handles, labels = output.legend_elements(prop=\"colors\", alpha=1)\n",
    "plt.legend(handles, labels, loc=\"upper right\", title=\"Abstract count at this point\", frameon=False)\n",
    "plt.show()\n",
    "\n",
    "# right click on the plot to save it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
